# 图像分类流程

## 系列简介

本系列将介绍Stanford深度学习课程的主要内容，做以下说明：本系列不是对原视频翻译，而是对每一课的主要内容进行说明及补充，其中关于课程中的行政事务我们将不做说明。 由于水平有限，在文章中难免出现错误，希望各位多多包含，帮助指正。

本文为该课程第二篇，主要介绍图像分类的一般流程。

## 图像数据组成

这部分课程中没有，算是图像处理的最基本的知识。本文为没有做过图像处理或者不了解图片组成的读者进行一个简单的介绍。

图像就是通常使用相机、手机等设备拍摄的照片，真实世界的场景想要被计算机所识别，所存储，就必须要将照片转化为计算机可以识别的格式。图像又称为数字图像，因为在计算机里，图像是以数字形式存储的。

现在我们最常见的照片都是彩色照片，彩色照片一般为RGB格式或者CMYK格式，本文介绍RGB格式。R代表红色（Red），G代表绿色（Green），B代表蓝色（Blue），红色、绿色、蓝色被称为三原色，通过不同比例的三种颜色的组合可以组合出各种各样的颜色。通常衡量图片大小是以像素来衡量的，什么800万像素啊，1500万像素之类的。像素可以理解为一个小的正方形区域，比如下面一张图片，它的大小为358 * 360，也就是说该图片可以看成358列360行的方格，每一个小方格就是一个像素。

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/Logo_%E6%96%B9.jpg)

同时我们看到，图片是彩色图片，所以每个像素上面会有三个数值R（Red），G（Green），B（Blue），三个数值的取值范围都为0-255。对于R来说，0代表正红色，255代表白色，之间眼色渐进，共256种不同的红色，对于蓝色和绿色也是一样，所以RGB图像可以表示256 * 256 * 256 种不同的颜色。

若是将图片数据读入到计算机中，该图片就是一个三维的矩阵，矩阵大小为 358 * 360 * 3，358 代表宽度，360代表高度，3代表深度（R，G，B）。


## 图像分类的困难

图像分类很困难，因为有很多因素会影响分类结果，列举如下（图片来自于Stanford课程）：

1. 图片的亮度不同

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/001.png)
![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/002.png)

从上面的四张图片都是猫，人一眼就能判断出来，但是对于计算机，这几张照片差异很大，比如前两张的猫都是暗色，且背景也是暗色，第三张的猫和背景都是亮色，而第四张猫是暗色，背景光为亮色。

2. 图片中的物体有不同的形状

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/003.png)
![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/004.png)

还是猫，不是每只猫的动作不一样，给计算机增加了不少难度。

3. 环境遮挡

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/005.png)

上图中的猫被环境中的物体遮挡住了部分身体，也会给计算机进行图像分类增加很大难度。特别第三张图片，人们可以根据露出的一个尾巴及周围的环境猜出那里极有可能是一只猫，但是这对计算机来说很难。

4. 背景混淆

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/006.png)

上面两个图中，猫的颜色和背景颜色很像，给计算机增加了区分难度。

5. 图像重叠

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/007.png)

图上都多只猫相互有重叠遮挡。

## 图像分类

分类的机器学习步骤一般如下：

1. 收集数据，并将数据图片和对应的分类标记好
2. 使用机器学习训练一个分类器
3. 使用训练好的分类器判断新的图片的属类


## 最邻近算法

最邻近算法应该可以说是最简单的分类器了，算法思想如下：对于任意一个测试图片，查看测试图片与所有训练图片的距离，选出与测试图片距离最近的训练图片，然后将该训练图片的类别作为测试图片的类别。前面说到了距离最近，所以需要选择一个距离，常用的距离有L1和L2距离，这里以L1为例。
L1距离代表两个图片差的绝对值，下图为一个简单示例。

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/008.png)

该算法实现起来也非常简单，对于一个分类器，需要一个训练的函数以及一个预测的函数。

```python
import numpy as np

class NearestNeighbor:
  def __init__(self):
    pass
  
  def train(self, X, y):
    self.Xtr = X
    self.ytr = y
    
  def test(self, X):
    num_test = X.shape[0]
    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)
    
    for i in xrange(num_test):
      distances = np.sum(np.abs(self.Xtr - X[i, :]), axis = 1)
      min_index = np.argmin(distances)
      Ypred[i] = self.ytr[min_index]
    return Ypred
  
```

上面的NearestNeighbor类中，有train和predict两个函数，train函数实现的很简单，就是记住训练数据，就是将训练图片与对应的分类记录下来。predict函数也很简单，就是对每一个测试图片，计算该测试图片与所有训练图片的L1距离，然后取出具有最小距离的图片的分类作为预测的类别。


