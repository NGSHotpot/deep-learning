# 图像分类流程

## 系列简介

本系列将介绍Stanford深度学习课程的主要内容，做以下说明：本系列不是对原视频翻译，而是对每一课的主要内容进行说明及补充，其中关于课程中的行政事务我们将不做说明。 由于水平有限，在文章中难免出现错误，希望各位多多包含，帮助指正。

本文为该课程第二篇，主要介绍图像分类的一般流程。

## 图像数据组成

这部分课程中没有，算是图像处理的最基本的知识。本文为没有做过图像处理或者不了解图片组成的读者进行一个简单的介绍。

图像就是通常使用相机、手机等设备拍摄的照片，真实世界的场景想要被计算机所识别，所存储，就必须要将照片转化为计算机可以识别的格式。图像又称为数字图像，因为在计算机里，图像是以数字形式存储的。

现在我们最常见的照片都是彩色照片，彩色照片一般为RGB格式或者CMYK格式，本文介绍RGB格式。R代表红色（Red），G代表绿色（Green），B代表蓝色（Blue），红色、绿色、蓝色被称为三原色，通过不同比例的三种颜色的组合可以组合出各种各样的颜色。通常衡量图片大小是以像素来衡量的，什么800万像素啊，1500万像素之类的。像素可以理解为一个小的正方形区域，比如下面一张图片，它的大小为358 * 360，也就是说该图片可以看成358列360行的方格，每一个小方格就是一个像素。

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/Logo_%E6%96%B9.jpg)

同时我们看到，图片是彩色图片，所以每个像素上面会有三个数值R（Red），G（Green），B（Blue），三个数值的取值范围都为0-255。对于R来说，0代表正红色，255代表白色，之间眼色渐进，共256种不同的红色，对于蓝色和绿色也是一样，所以RGB图像可以表示256 * 256 * 256 种不同的颜色。

若是将图片数据读入到计算机中，该图片就是一个三维的矩阵，矩阵大小为 358 * 360 * 3，358 代表宽度，360代表高度，3代表深度（R，G，B）。


## 图像分类的困难

图像分类很困难，因为有很多因素会影响分类结果，列举如下（图片来自于Stanford课程）：

1. 图片的亮度不同

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/001.png)

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/002.png)

从上面的四张图片都是猫，人一眼就能判断出来，但是对于计算机，这几张照片差异很大，比如前两张的猫都是暗色，且背景也是暗色，第三张的猫和背景都是亮色，而第四张猫是暗色，背景光为亮色。

2. 图片中的物体有不同的形状

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/003.png)

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/004.png)

还是猫，不是每只猫的动作不一样，给计算机增加了不少难度。

3. 环境遮挡

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/005.png)

上图中的猫被环境中的物体遮挡住了部分身体，也会给计算机进行图像分类增加很大难度
