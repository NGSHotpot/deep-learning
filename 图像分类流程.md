# 图像分类流程

## 系列简介

本系列将介绍Stanford深度学习课程的主要内容，做以下说明：本系列不是对原视频翻译，而是对每一课的主要内容进行说明及补充，其中关于课程中的行政事务我们将不做说明。 由于水平有限，在文章中难免出现错误，希望各位多多包含，帮助指正。

本文为该课程第二篇，主要介绍图像分类的一般流程。

## 图像数据组成

这部分课程中没有，算是图像处理的最基本的知识。本文为没有做过图像处理或者不了解图片组成的读者进行一个简单的介绍。

图像就是通常使用相机、手机等设备拍摄的照片，真实世界的场景想要被计算机所识别，所存储，就必须要将照片转化为计算机可以识别的格式。图像又称为数字图像，因为在计算机里，图像是以数字形式存储的。

现在我们最常见的照片都是彩色照片，彩色照片一般为RGB格式或者CMYK格式，本文介绍RGB格式。R代表红色（Red），G代表绿色（Green），B代表蓝色（Blue），红色、绿色、蓝色被称为三原色，通过不同比例的三种颜色的组合可以组合出各种各样的颜色。通常衡量图片大小是以像素来衡量的，什么800万像素啊，1500万像素之类的。像素可以理解为一个小的正方形区域，比如下面一张图片，它的大小为358 * 360，也就是说该图片可以看成358列360行的方格，每一个小方格就是一个像素。

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/Logo_%E6%96%B9.jpg)

同时我们看到，图片是彩色图片，所以每个像素上面会有三个数值R（Red），G（Green），B（Blue），三个数值的取值范围都为0-255。对于R来说，0代表正红色，255代表白色，之间眼色渐进，共256种不同的红色，对于蓝色和绿色也是一样，所以RGB图像可以表示256 * 256 * 256 种不同的颜色。

若是将图片数据读入到计算机中，该图片就是一个三维的矩阵，矩阵大小为 358 * 360 * 3，358 代表宽度，360代表高度，3代表深度（R，G，B）。


## 图像分类的困难

图像分类很困难，因为有很多因素会影响分类结果，列举如下（图片来自于Stanford课程）：

1. 图片的亮度不同

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/001.png)
![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/002.png)

从上面的四张图片都是猫，人一眼就能判断出来，但是对于计算机，这几张照片差异很大，比如前两张的猫都是暗色，且背景也是暗色，第三张的猫和背景都是亮色，而第四张猫是暗色，背景光为亮色。

2. 图片中的物体有不同的形状

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/003.png)
![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/004.png)

还是猫，不是每只猫的动作不一样，给计算机增加了不少难度。

3. 环境遮挡

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/005.png)

上图中的猫被环境中的物体遮挡住了部分身体，也会给计算机进行图像分类增加很大难度。特别第三张图片，人们可以根据露出的一个尾巴及周围的环境猜出那里极有可能是一只猫，但是这对计算机来说很难。

4. 背景混淆

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/006.png)

上面两个图中，猫的颜色和背景颜色很像，给计算机增加了区分难度。

5. 图像重叠

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/007.png)

图上都多只猫相互有重叠遮挡。

## 图像分类

分类的机器学习步骤一般如下：

1. 收集数据，并将数据图片和对应的分类标记好
2. 使用机器学习训练一个分类器
3. 使用训练好的分类器判断新的图片的属类


## 最邻近算法

最邻近算法应该可以说是最简单的分类器了，算法思想如下：对于任意一个测试图片，查看测试图片与所有训练图片的距离，选出与测试图片距离最近的训练图片，然后将该训练图片的类别作为测试图片的类别。前面说到了距离最近，所以需要选择一个距离，常用的距离有L1和L2距离，这里以L1为例。
L1距离代表两个图片差的绝对值，下图为一个简单示例。

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/008.png)

该算法实现起来也非常简单，对于一个分类器，需要一个训练的函数以及一个预测的函数。

```python
import numpy as np

class NearestNeighbor:
  def __init__(self):
    pass
  
  def train(self, X, y):
    self.Xtr = X
    self.ytr = y
    
  def test(self, X):
    num_test = X.shape[0]
    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)
    
    for i in xrange(num_test):
      distances = np.sum(np.abs(self.Xtr - X[i, :]), axis = 1)
      min_index = np.argmin(distances)
      Ypred[i] = self.ytr[min_index]
    return Ypred
  
```

上面的NearestNeighbor类中，有train和predict两个函数，train函数实现的很简单，就是记住训练数据，就是将训练图片与对应的分类记录下来。predict函数也很简单，就是对每一个测试图片，计算该测试图片与所有训练图片的L1距离，然后取出具有最小距离的图片的分类作为预测的类别。

上面的函数，假如训练样本有10000张照片，测试照片有100张，我们来看看完成上述的训练与预测需要计算次数。对于训练，显然只需要执行10000照片的存储。对于测试，对每一张测试照片我们都需要访问所有的10000张照片一次，所以若是100张照片，我们需要执行10000 * 100 = 1000000 次。这不是一个好的机器学习分类模型！一个好的机器学习分类模型我们希望预测的时间越短越好，相反训练时间稍长也没有关系，因为对于一个模型，一般情况下我们只需要训练一次，而需要预测很多次。

## 最邻近算法效果

以上的最邻近算法会产生什么样的效果呢？下面是一个示例：

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture2/009.png)

上图中带颜色的点代表训练数据，不同的颜色代表不同的分类。现在假如有个测试样例，如果使用最邻近算法，那么这个测试样例该如何分布呢？后面的背景颜色区域标识着：若测试样本中间绿色区域，那么该测试样本会被分类为绿色类，对其他区域有相同的效果。从上面结果我们可以看到绿色区域的中间有个黄色区域，该黄色区域是由于训练数据中有一个黄色的点位于绿色点中间，该点可以理解为一个outlier。所以上面的最邻近算法给出的结果不是我们理想的结果，那么有什么办法解决这个问题呢？

## K邻近算法

上面说了最邻近算法的效果，最邻近算法中会出现一些问题，那么可以以K邻近算法来优化这个问题。K邻近算法大概是这样的：训练时和最邻近算法相同，但是测试时，我们不再寻找与测试图片最近的训练图片，而是找到K张与该测试图片最近的训练图片，然后将这K个训练图片大部分所属的类别作为该测试图片的预测类别。

下面说一下如何实现K邻近算法（这部分课程没有）

```python
import numpy as np
from scipy.stats import mode

class KNearestNeighbor:
  def __init__(self):
    pass
  
  def train(self, X, y):
    self.Xtr = X
    self.ytr = y
    
  def test(self, X, K):
    num_test = X.shape[0]
    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)
    
    for i in xrange(num_test):
      distances = np.sum(np.abs(self.Xtr - X[i, :]), axis = 1)
      sort_index = np.argsort(distances)
      min_index = sort_index[:K]
      k_ytr = [self.ytr[tmp_index] for tmp_index in min_index]
      pred, pred_count = mode(k_ytr)
      if pred_count[0] == 1:
        Ypred[i] = -1
      else:
        Ypred[i] = pred[0]
    return Ypred
  
```

上述程序要想成功，我们需要设定图片的分类为数字，1,2,3,4等等。若是K个最邻近的训练数据中，每个数据都属于不同的分类，那么返回-1，说明该测试集不能判断属于哪个类。



