# 损失函数及最优化

## 系列简介

本系列将介绍Stanford深度学习课程的主要内容，做以下说明：本系列不是对原视频翻译，而是对每一课的主要内容进行说明及补充，其中关于课程中的行政事务我们将不做说明。 由于水平有限，在文章中难免出现错误，希望各位多多包含，帮助指正。

本文为该课程第三篇，介绍损失函数及最优化的相关内容。


## 线性分类模型

在前面图像分类流程中，我们介绍了线性分类模型，可以将线性分类模型简化为![equation](http://latex.codecogs.com/gif.latex?Y=Wx)。容易知道，对于训练数据来说![equation](http://latex.codecogs.com/gif.latex?Y)和![equation](http://latex.codecogs.com/gif.latex?x)都是已知的，但是![equation](http://latex.codecogs.com/gif.latex?W)是未知的。前面一节的内容中是直接给出了一组![equation](http://latex.codecogs.com/gif.latex?W)的值，那么问题来了：这组权重是怎么得出来的？这组权重好吗？如果不好，怎么得到更好的权重？

本节的主要内容主要包括：

1. 如何评估已有的一组权重的好坏？损失函数（loss function）
2. 如何得到并优化权重？最优化（Optimization）


## 损失函数

首先说一个例子，比如在CIFAR-10中，要对图片进行分类，选择十个分类中的一个。根据前面的线性分类模型，![equation](http://latex.codecogs.com/gif.latex?Y=Wx)应该是一个长度为10的向量，这10个值分别表示这个图片为对应着的分类的数值。比如下图为分别对猫、轿车、青蛙进行分类的一个结果，可以看到第一张图片被分类为猫的数值为2.9，但是这列中最大值为8.02，所以这张猫的图片被错误的分类成了狗。同样的，第二张照片被分类成轿车的数值是6.04，为这一列中最大值，所以该图片正确分类。第三张照片被分类成青蛙的数值为-4.34，而最大值为6.14，显然是错误分类。

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture3/0.png)

所以上面的分类结果对应的权重矩阵对于中间的轿车是好的，但是对于猫和青蛙就是不好的。根据数值来说，我们直觉上可以觉得，猫的分类效果比青蛙好一些，因为我们可以看到猫的数值2.9距离最大值8.02差距只有大概5.12，而青蛙的数值-4.34距离最大值6.14有10.48，猫相对来说要准确一些。但是这个只是直觉，损失函数做的事情就是讲分类正确性的这种“直觉”量化出来。或者这么说，如果分类正确了，我们就很开心，如果分类不正确，我们就不开心，分类错的越严重，我们不开心程度就越重，此时损失函数就是用来衡量我们不开心的程度的函数。

为了更加清晰的说明损失函数，从上面的10分类问题变成研究3分类问题，只分类图片属于猫、汽车、青蛙中的哪一个。这里设置的数值和上面例子类似，猫和青蛙都没有被正确分类，但是直觉上猫的情况会比青蛙好一些，而汽车被正确分类。

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture3/1.png)

损失函数定义如下：若是设定一个数据集![equation](http://latex.codecogs.com/gif.latex?\left\{(x_i,y_i)\right\}_{i=1}^{N}),其中![equation](http://latex.codecogs.com/gif.latex?X_i)为输入图片（数据），![equation](http://latex.codecogs.com/gif.latex?Y_i)为该图片（数据）所属分类（标签），![equation](http://latex.codecogs.com/gif.latex?N)为数据集中样本数量。在此基础上可以定义预测函数为

![equation](http://latex.codecogs.com/gif.latex?f(X_i,W)),

单个样本的损失定义为

![equation](http://latex.codecogs.com/gif.latex?L_i(f(X_i,W),Y_i))，

用于衡量预测值与真实值的差异，然后损失函数可以定义为

![equation](http://latex.codecogs.com/gif.latex?\frac{1}{N}\sum_{i}L_i(f(X_i,W),Y_i))，

衡量当前参数对于在所有的数据集中的平均损失程度，一个好的分类器，既然名字叫损失，当然希望损失越小越好，所以在定义![equation](http://latex.codecogs.com/gif.latex?L_i)的时候需要把握若是当预测正确时，没有损失，若是预测错得越厉害，损失越大。

## SVM损失函数

一种常用的损失函数是Hinge损失函数，SVM算法中使用的就是这个损失函数，所以也叫SVM损失函数。对每一个输入的图片，可以通过预测函数![equation](http://latex.codecogs.com/gif.latex?f(X_i,W))预测得到该图片属于每一个分类的数值，这里还是以上面说的三分类来说明，所以预测结果应该是长度为3的向量。下面令

![equation](http://latex.codecogs.com/gif.latex?s=f(X_i,W))

并且![equation](http://latex.codecogs.com/gif.latex?Y_i=1,2,3)中的其中一个，代表![equation](http://latex.codecogs.com/gif.latex?Y_i)属于第一分类、第二分类、第三分类。SVM损失函数定义为：

![equation](http://latex.codecogs.com/gif.latex?L_i=\sum_{j\ne{y_i}}(0,s_j-s_{y_i}+1))

其含义为，对于某个样本来说，在三个分类中，有一个正确类别，两个错误类别。对于每一个错误类别，若是正确类别的数值比该错误类别的数值至少大于1，那么认为这个错误分类的损失为0，否则认为其损失为该错误类别数值与正确类别数值之差再减1。也就是说若是错误类别数值相对于正确类别数值越大，损失也越大。三个类别中有两个是错误类别，所以两个错误类别的损失加起来也就是当前这个样本的损失了。当然这里的定义的要求正确数值比错误类别数值大1，这里的1是可以根据实际数据情况自己定义的。

说这么多，说得也不清楚，不如直接看个例子，还是刚才的三分类问题，如下图所示：

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/lecture3/1.png)

对于第一个样本猫来说，正确分类是第一个分类，第二个类别和第三个类别都是错误分类。所以第一个样本的损失为：

![equation](http://latex.codecogs.com/gif.latex?L_1=max(0,5.1-3.2+1)+max(0,-1.7-3.2+1))

![equation](http://latex.codecogs.com/gif.latex?=max(0,2.9)+max(0,-3.9)=2.9+0=2.9)

对于第二个样本猫来说，正确分类是第二个分类，第一个类别和第三个类别都是错误分类。所以第二个样本的损失为：

![equation](http://latex.codecogs.com/gif.latex?L_2=max(0,1.3-4.9+1)+max(0,2.0-4.9+1))

![equation](http://latex.codecogs.com/gif.latex?=max(0,-2.6)+max(0,-1.9)=0+0=0)

对于第三个样本猫来说，正确分类是第三个分类，第一个类别和第二个类别都是错误分类。所以第三个样本的损失为：

![equation](http://latex.codecogs.com/gif.latex?L_3=max(0,2.2-(-3.1)+1)+max(0,2.5-(-3.1)+1))

![equation](http://latex.codecogs.com/gif.latex?=max(0,6.3)+max(0,6.6)=6.3+6.6=12.9)

所以对于所有的三个样本来说，其损失函数为三个样本上损失的平均值：

![equation](http://latex.codecogs.com/gif.latex?L=(L_1+L_2+L_3)/3=(2.9+0+12.9)/3=5.27)

所以对于这个样例来说其损失函数值为5.27，通过这个例子应该就很清楚SVM损失函数是如何计算的了。







