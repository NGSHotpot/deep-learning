# 卷积神经网络简介

## 系列简介

本系列将介绍Stanford深度学习课程的主要内容，做以下说明：本系列不是对原视频翻译，而是对每一课的主要内容进行说明及补充，其中关于课程中的行政事务我们将不做说明。
由于水平有限，在文章中难免出现错误，希望各位多多包含，帮助指正。

本文为该课程第一篇，对卷积神经网络进行介绍。

## 内容简介

该课程第一篇比较简单，主要为介绍计算机视觉的一些基本概况，以及现阶段卷积神经网络的一些成果，用来让大家了解大致概要。

## 计算机视觉

人类接收信息的大约80%都来自于人类的视觉系统，随着科技的发展，出现了很多可以产生图片或者视频的设备，比如我们的手机和相机可以不断的拍照或者录视频。在我们每天的生活中都有大量的图像信息在产生，并且被大家上传到网上。如此大量的图像信息，凭借人眼根本无法很好的从海量的图像中提取出想要的信息。所以人们逐渐在想办法让计算机可以“读懂”图像中的信息，这就是计算视觉。

计算机视觉是一个较为复杂的研究方向，涵盖了很多现有的学科。计算机视觉需要物理学，因为我们需要对光学及图像的形成过程有一定的理解；计算机视觉也需要生物学，因为我们需要知道大脑是如何去看见图像并处理图像信息的；计算机视觉也需要心理学，因为我们需要了解人类或者动物行为的意义；计算机视觉显然也是需要计算机科学、数学以及工程学的，因为我们需要建立计算机系统来实现我们的计算机视觉算法。

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/001.png)

## 计算机视觉的历史

这部分简单说明，没有将课程中所有的内容包括进来。

生物的视觉大约产生于5.4亿年以前，视觉的出现让当时地球上的生物数量出现了爆炸式的增长。1959年，Hubel和Wiesel通过猫进行试验，发现了视觉神经元的不同作用，他们发现并定义了两种不同的视觉神经元细胞：简单细胞和复杂细胞。简单神经元细胞是指那些只对光的位置和强度有反应的神经元，复杂神经元细胞是指那些不仅对光的强度和位置有反应，而且对光的运动有反应的神经元。

随着1545年，第一台相机产生，到1963年，第一篇计算机视觉相关的研究产生，从1966年斯坦福的暑期视觉项目开始，到现在已经有无数的研究者在进行计算机视觉相关的研究。现在计算机视觉正在蓬勃发展。

## 数据集

这部分在原课程中进行了较大拓展，会介绍较多比较著名的计算机视觉数据集。

在课程中提到了PASCAL VOL 数据集及ImageNet数据集，下面列表出11个数据集的大致情况（可能另起一篇详细介绍这些数据集）


| 数据库         | 图像条目           | 类别数目  | 
| :-----------: |:-------------:| :----:| 
| MNIST         | 70000       | 10     | 
| CIFAR-10	    | 60000	      | 10 	   |
| MPEG-7        | 1400	      | 70	   |
| 15 Scenes     | 4485        | 15     | 
| Caltech-101	  | 9146	      | 101	   |
| Caltech-256	  | 30607	      | 256	   |
| PASCAL VOC	  | 11530	      | 20	   |
| SUN397    	  | 108754	    | 397	   |
| SUN2012	      | 16873	      | 8  	   |
| Tiny Images   | 7900万      | 75062  |
| ImageNet      | 1400万      | 22000  |


## ImageNet 图像分类竞赛

ImageNet是Fei-Fei Li做的数据库，前几年很多大牛都在该数据库上参加图像分类竞赛，从而不断刷新图像处理的精度。每一次竞赛中，数据集包含1000个分类，1,431,167张图片。

图像分类的精度一般以Top-5 error rate来衡量，也就是对于每一张图像，参赛者的算法可以给出自己认为的这张图像属于的最可能的五个分类，看五个分类中是否有正确的分类。

下面的图片是课程中的对2015年以前错误率的一个统计

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/002.png)

从图中可以看到，从2010年到2015年，Top-5 错误率在逐年下降：从2010年的28.2%的错误率下降到2015年的3.57%的错误率。人类平均错误率大约为5.1%，到2015年在该竞赛中，计算机视觉算法已经超过人类。近两年的冠军成绩课程中没有提到，大家可以到ImageNet官网去查看（http://image-net.org/ ）。2016年Top-5错误率为2.99%，2017年Top-5错误率为2.25%。 ImageNet竞赛2017年竞赛为该竞赛最后一年竞赛。

在上图中可以看到，在2012年错误率有很大幅度的下降（从2011年的25.8%到2012年的16.4%），是Hinton带领其博士研究生Alex等构建的卷积神经网络创造的。卷积神经网络在2012年ImageNet上取得的成就是卷积神经网络及深度学习发展的一个重要里程碑。之后的几年在ImageNet上取得冠军的策略都是卷积神经网络，比著名的为2014年牛津大学的VGG，2014年Google的GoogleNet（Inception），2015年微软的ResNet等 （在后期推文中我们也会对所有的这些经典模型进行解读）。

上面主要由Fei-Fei Li讲解，后面主要内容由Fei-Fei Li的博士研究生Justin Johnson讲解。

## 课程主要目标

cs231n课程主要集中在图像分类上，图像分类是一个非常重要的图像识别问题。也会介绍其他一些和图像分类相关的图像处理任务，如图像目标检测及图片说明（看图说话）。

图像分类基本可以理解为：给你一张图片，你写计算机视觉算法判断这张图片是什么种类，比如狗、猫、汽车、飞机等。

图像目标检测可以不仅仅要做图像分类，而且需要在图像上标出判断出来的分类在什么位置，比如狗在图像的左上角等，一般将识别到的区域用方框框起来。

图片说明理解起来也比较简单，就是我们小学做的看图说话，只是现在要让计算机看图说话。

## 卷积神经网络与图像识别

卷积神经网络推动着图像识别的迅速发展，卷积神经网络在ImageNet上取得了巨大成功并且不断更新着识别记录，但是卷积神经网络并不是马上就有了的。最初的卷积神经网络比较公认的是LeCun在1998年提出的卷积神经网络。下面是LeCun的卷积神经网络和Alex的卷积神经网络，我们可以观察一下。

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/003.png)

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/004.png)

大家可能已经发现了，他们的网络结构特别像，只是AlexNet稍微多几层。那为什么LeCun当时没有取得这么好的效果呢？主要两个原因，一是计算能力，在LeCun做出卷积神经网络的时候计算机还很慢，想想98年的时候我们还是win98，而现在已经win10了，还有GPU进行大规模并行运算。二是数据，98年时候数据集很有限，现在ImageNet提供了大量的额数据集，为卷积神经网络的发展提供了基础。

## 计算机视觉还有很远的路要走

虽然现阶段卷积神经网络已经很强大了，但还是有很多问题。比如卷积神经网络虽然可以识别到图像中有几个人物，能够知道他们大致是什么动作，但是确很难知道他们在做什么，而人类可以去想像他们可能是在进行某种运动等等。课程中另外还举例了奥巴马的例子（感兴趣的可以去看看）。

## 课程推荐深度学习书籍

![](https://github.com/NGSHotpot/deep-learning/blob/master/stanford_img/005.png)

《Deep Learning》 是由Ian Goodfellow，Yoshua Bengio，Aaron Courville写的，有github链接，大家可以自行下载阅读

https://github.com/HFTrader/DeepLearningBook

## 课程前所需知识

1. 熟练使用Python，对C/C++较为熟悉
2. 大学数学分析、线性代数
3. 机器学习知识 （cs229）

## 索引

下一讲： [Stanford深度学习课程|第二课图像分类流程](https://github.com/NGSHotpot/deep-learning/blob/master/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%B5%81%E7%A8%8B.md)

